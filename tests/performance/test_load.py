"""
AIé‡åŒ–ç³»ç»Ÿæ€§èƒ½å’Œå‹åŠ›æµ‹è¯•
æµ‹è¯•ç³»ç»Ÿåœ¨é«˜è´Ÿè½½ä¸‹çš„æ€§èƒ½è¡¨ç°
"""

import pytest
import asyncio
import time
import concurrent.futures
import sys
import statistics
from typing import List, Dict, Tuple
from datetime import datetime, date
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent))

from backend.src.data.akshare_adapter import AKShareAdapter
from backend.src.storage.parquet_engine import ParquetStorage
from backend.src.models.basic_models import StockData, StockDailyBar


class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self):
        self.response_times: List[float] = []
        self.success_count: int = 0
        self.error_count: int = 0
        self.throughput: float = 0.0
        self.start_time: float = 0.0
        self.end_time: float = 0.0
    
    def add_response_time(self, response_time: float, success: bool = True):
        """æ·»åŠ å“åº”æ—¶é—´è®°å½•"""
        self.response_times.append(response_time)
        if success:
            self.success_count += 1
        else:
            self.error_count += 1
    
    def calculate_metrics(self) -> Dict[str, float]:
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        total_requests = self.success_count + self.error_count
        duration = self.end_time - self.start_time
        
        metrics = {
            "total_requests": total_requests,
            "success_rate": (self.success_count / total_requests * 100) if total_requests > 0 else 0,
            "error_rate": (self.error_count / total_requests * 100) if total_requests > 0 else 0,
            "duration": duration,
            "throughput": total_requests / duration if duration > 0 else 0,
            "avg_response_time": statistics.mean(self.response_times) if self.response_times else 0,
            "min_response_time": min(self.response_times) if self.response_times else 0,
            "max_response_time": max(self.response_times) if self.response_times else 0,
            "p95_response_time": statistics.quantiles(self.response_times, n=20)[18] if len(self.response_times) >= 20 else 0,
            "p99_response_time": statistics.quantiles(self.response_times, n=100)[98] if len(self.response_times) >= 100 else 0,
        }
        
        return metrics


class TestPerformance:
    """æ€§èƒ½å’Œå‹åŠ›æµ‹è¯•ç±»"""
    
    @pytest.fixture(scope="class", autouse=True)
    def setup_test_environment(self, request):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®ç›®å½•
        test_data_dir = Path("data/performance_test")
        test_data_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–ç»„ä»¶
        request.cls.akshare_adapter = AKShareAdapter()
        request.cls.parquet_storage = ParquetStorage(base_path="data/performance_test/parquet")

        yield

        # æ¸…ç†æµ‹è¯•æ•°æ®
        import shutil
        if test_data_dir.exists():
            shutil.rmtree(test_data_dir)
    
    def test_data_fetch_performance(self):
        """æµ‹è¯•æ•°æ®è·å–æ€§èƒ½"""
        print("\n=== æ•°æ®è·å–æ€§èƒ½æµ‹è¯• ===")
        
        test_symbols = ["000001", "000002", "600000", "600036", "000858"]
        metrics = PerformanceMetrics()
        metrics.start_time = time.time()
        
        print(f"æµ‹è¯•è‚¡ç¥¨æ•°é‡: {len(test_symbols)}")
        print("å¼€å§‹æ•°æ®è·å–æ€§èƒ½æµ‹è¯•...")
        
        for i, symbol in enumerate(test_symbols, 1):
            start_time = time.time()
            success = False
            
            try:
                stock_data = self.akshare_adapter.get_stock_daily_data(
                    symbol=symbol,
                    start_date="2024-01-01", 
                    end_date="2024-01-10"
                )
                
                if stock_data and len(stock_data.bars) > 0:
                    success = True
                    print(f"  [{i}/{len(test_symbols)}] âœ“ {symbol}: {len(stock_data.bars)} æ¡æ•°æ®")
                else:
                    print(f"  [{i}/{len(test_symbols)}] âœ— {symbol}: æ— æ•°æ®")
                    
            except Exception as e:
                print(f"  [{i}/{len(test_symbols)}] âœ— {symbol}: {e}")
            
            response_time = time.time() - start_time
            metrics.add_response_time(response_time, success)
        
        metrics.end_time = time.time()
        perf_metrics = metrics.calculate_metrics()
        
        # æ‰“å°æ€§èƒ½æŒ‡æ ‡
        print(f"\næ•°æ®è·å–æ€§èƒ½æŒ‡æ ‡:")
        print(f"  æ€»è¯·æ±‚æ•°: {perf_metrics['total_requests']}")
        print(f"  æˆåŠŸç‡: {perf_metrics['success_rate']:.1f}%")
        print(f"  å¹³å‡å“åº”æ—¶é—´: {perf_metrics['avg_response_time']:.3f}ç§’")
        print(f"  æœ€å¤§å“åº”æ—¶é—´: {perf_metrics['max_response_time']:.3f}ç§’")
        print(f"  P95å“åº”æ—¶é—´: {perf_metrics['p95_response_time']:.3f}ç§’")
        print(f"  ååé‡: {perf_metrics['throughput']:.2f} è¯·æ±‚/ç§’")
        
        # æ€§èƒ½æ–­è¨€
        assert perf_metrics['success_rate'] >= 80, f"æˆåŠŸç‡ {perf_metrics['success_rate']:.1f}% ä½äº80%"
        assert perf_metrics['avg_response_time'] <= 5.0, f"å¹³å‡å“åº”æ—¶é—´ {perf_metrics['avg_response_time']:.3f}s è¶…è¿‡5ç§’"
        
        print("âœ“ æ•°æ®è·å–æ€§èƒ½æµ‹è¯•é€šè¿‡")
    
    def test_storage_performance(self):
        """æµ‹è¯•å­˜å‚¨æ€§èƒ½"""
        print("\n=== å­˜å‚¨æ€§èƒ½æµ‹è¯• ===")
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        test_data_count = 10
        test_records_per_stock = 100
        
        print(f"ç”Ÿæˆ {test_data_count} åªè‚¡ç¥¨çš„æµ‹è¯•æ•°æ®ï¼Œæ¯åªè‚¡ç¥¨ {test_records_per_stock} æ¡è®°å½•")
        
        test_stocks = []
        for i in range(test_data_count):
            symbol = f"TEST{i:03d}"
            bars = []
            
            for j in range(test_records_per_stock):
                bar = StockDailyBar(
                    date=date(2024, 1, j % 28 + 1),
                    open_price=100.0 + j * 0.1,
                    close_price=100.5 + j * 0.1,
                    high_price=101.0 + j * 0.1,
                    low_price=99.5 + j * 0.1,
                    volume=1000000 + j * 1000
                )
                bars.append(bar)
            
            test_stocks.append(StockData(symbol=symbol, bars=bars))
        
        # æµ‹è¯•å­˜å‚¨æ€§èƒ½
        metrics = PerformanceMetrics()
        metrics.start_time = time.time()
        
        print("å¼€å§‹å­˜å‚¨æ€§èƒ½æµ‹è¯•...")
        for i, stock_data in enumerate(test_stocks, 1):
            start_time = time.time()
            success = False
            
            try:
                self.parquet_storage.save_stock_data(stock_data)
                success = True
                print(f"  [{i}/{len(test_stocks)}] âœ“ å­˜å‚¨ {stock_data.symbol}")
            except Exception as e:
                print(f"  [{i}/{len(test_stocks)}] âœ— å­˜å‚¨ {stock_data.symbol}: {e}")
            
            response_time = time.time() - start_time
            metrics.add_response_time(response_time, success)
        
        metrics.end_time = time.time()
        perf_metrics = metrics.calculate_metrics()
        
        # æ‰“å°å­˜å‚¨æ€§èƒ½æŒ‡æ ‡
        print(f"\nå­˜å‚¨æ€§èƒ½æŒ‡æ ‡:")
        print(f"  æ€»å­˜å‚¨ä»»åŠ¡: {perf_metrics['total_requests']}")
        print(f"  æˆåŠŸç‡: {perf_metrics['success_rate']:.1f}%")
        print(f"  å¹³å‡å­˜å‚¨æ—¶é—´: {perf_metrics['avg_response_time']:.3f}ç§’")
        print(f"  æœ€å¤§å­˜å‚¨æ—¶é—´: {perf_metrics['max_response_time']:.3f}ç§’")
        print(f"  å­˜å‚¨ååé‡: {perf_metrics['throughput']:.2f} æ–‡ä»¶/ç§’")
        
        # æµ‹è¯•è¯»å–æ€§èƒ½
        print("\nå¼€å§‹è¯»å–æ€§èƒ½æµ‹è¯•...")
        read_metrics = PerformanceMetrics()
        read_metrics.start_time = time.time()
        
        for i, stock_data in enumerate(test_stocks, 1):
            start_time = time.time()
            success = False
            
            try:
                retrieved_data = self.parquet_storage.load_stock_data(stock_data.symbol)
                if retrieved_data and len(retrieved_data.bars) > 0:
                    success = True
                    print(f"  [{i}/{len(test_stocks)}] âœ“ è¯»å– {stock_data.symbol}: {len(retrieved_data.bars)} æ¡")
                else:
                    print(f"  [{i}/{len(test_stocks)}] âœ— è¯»å– {stock_data.symbol}: æ— æ•°æ®")
            except Exception as e:
                print(f"  [{i}/{len(test_stocks)}] âœ— è¯»å– {stock_data.symbol}: {e}")
            
            response_time = time.time() - start_time
            read_metrics.add_response_time(response_time, success)
        
        read_metrics.end_time = time.time()
        read_perf_metrics = read_metrics.calculate_metrics()
        
        # æ‰“å°è¯»å–æ€§èƒ½æŒ‡æ ‡
        print(f"\nè¯»å–æ€§èƒ½æŒ‡æ ‡:")
        print(f"  æ€»è¯»å–ä»»åŠ¡: {read_perf_metrics['total_requests']}")
        print(f"  æˆåŠŸç‡: {read_perf_metrics['success_rate']:.1f}%")
        print(f"  å¹³å‡è¯»å–æ—¶é—´: {read_perf_metrics['avg_response_time']:.3f}ç§’")
        print(f"  æœ€å¤§è¯»å–æ—¶é—´: {read_perf_metrics['max_response_time']:.3f}ç§’")
        print(f"  è¯»å–ååé‡: {read_perf_metrics['throughput']:.2f} æ–‡ä»¶/ç§’")
        
        # æ€§èƒ½æ–­è¨€
        assert perf_metrics['success_rate'] >= 95, f"å­˜å‚¨æˆåŠŸç‡ {perf_metrics['success_rate']:.1f}% ä½äº95%"
        assert read_perf_metrics['success_rate'] >= 95, f"è¯»å–æˆåŠŸç‡ {read_perf_metrics['success_rate']:.1f}% ä½äº95%"
        assert perf_metrics['avg_response_time'] <= 1.0, f"å¹³å‡å­˜å‚¨æ—¶é—´ {perf_metrics['avg_response_time']:.3f}s è¶…è¿‡1ç§’"
        assert read_perf_metrics['avg_response_time'] <= 0.5, f"å¹³å‡è¯»å–æ—¶é—´ {read_perf_metrics['avg_response_time']:.3f}s è¶…è¿‡0.5ç§’"
        
        print("âœ“ å­˜å‚¨æ€§èƒ½æµ‹è¯•é€šè¿‡")
    
    def test_concurrent_operations(self):
        """æµ‹è¯•å¹¶å‘æ“ä½œæ€§èƒ½"""
        print("\n=== å¹¶å‘æ“ä½œæ€§èƒ½æµ‹è¯• ===")
        
        concurrent_workers = 5
        operations_per_worker = 3
        
        print(f"å¹¶å‘å·¥ä½œè€…: {concurrent_workers}")
        print(f"æ¯ä¸ªå·¥ä½œè€…æ“ä½œæ•°: {operations_per_worker}")
        
        def worker_task(worker_id: int) -> List[Tuple[str, float, bool]]:
            """å·¥ä½œè€…ä»»åŠ¡"""
            results = []
            
            for i in range(operations_per_worker):
                symbol = f"CONC{worker_id:02d}{i:02d}"
                
                # åˆ›å»ºæµ‹è¯•æ•°æ®
                test_data = StockData(
                    symbol=symbol,
                    bars=[
                        StockDailyBar(
                            date=date(2024, 1, 1),
                            open_price=100.0 + worker_id,
                            close_price=101.0 + worker_id,
                            high_price=102.0 + worker_id,
                            low_price=99.0 + worker_id,
                            volume=1000000 * (worker_id + 1)
                        )
                    ]
                )
                
                # å­˜å‚¨æ“ä½œ
                start_time = time.time()
                success = False
                
                try:
                    self.parquet_storage.save_stock_data(test_data)
                    
                    # ç«‹å³è¯»å–éªŒè¯
                    retrieved_data = self.parquet_storage.load_stock_data(symbol)
                    if retrieved_data and len(retrieved_data.bars) > 0:
                        success = True
                
                except Exception as e:
                    print(f"  Worker {worker_id} æ“ä½œ {symbol} å¤±è´¥: {e}")
                
                operation_time = time.time() - start_time
                results.append((symbol, operation_time, success))
            
            return results
        
        # å¹¶å‘æ‰§è¡Œ
        start_time = time.time()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_workers) as executor:
            futures = [executor.submit(worker_task, i) for i in range(concurrent_workers)]
            all_results = []
            
            for future in concurrent.futures.as_completed(futures):
                try:
                    results = future.result()
                    all_results.extend(results)
                except Exception as e:
                    print(f"  Worker æ‰§è¡Œå¼‚å¸¸: {e}")
        
        end_time = time.time()
        total_duration = end_time - start_time
        
        # åˆ†æç»“æœ
        total_operations = len(all_results)
        successful_operations = sum(1 for _, _, success in all_results if success)
        response_times = [rt for _, rt, _ in all_results]
        
        print(f"\nå¹¶å‘æ“ä½œç»“æœ:")
        print(f"  æ€»æ“ä½œæ•°: {total_operations}")
        print(f"  æˆåŠŸæ“ä½œæ•°: {successful_operations}")
        print(f"  æˆåŠŸç‡: {successful_operations / total_operations * 100:.1f}%")
        print(f"  æ€»è€—æ—¶: {total_duration:.2f}ç§’")
        print(f"  å¹³å‡æ“ä½œæ—¶é—´: {statistics.mean(response_times):.3f}ç§’")
        print(f"  å¹¶å‘ååé‡: {total_operations / total_duration:.2f} æ“ä½œ/ç§’")
        
        # å¹¶å‘æ€§èƒ½æ–­è¨€
        success_rate = successful_operations / total_operations * 100
        assert success_rate >= 90, f"å¹¶å‘æ“ä½œæˆåŠŸç‡ {success_rate:.1f}% ä½äº90%"
        assert statistics.mean(response_times) <= 2.0, f"å¹¶å‘å¹³å‡å“åº”æ—¶é—´è¶…è¿‡2ç§’"
        
        print("âœ“ å¹¶å‘æ“ä½œæ€§èƒ½æµ‹è¯•é€šè¿‡")
    
    def test_memory_usage(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        print("\n=== å†…å­˜ä½¿ç”¨æµ‹è¯• ===")
        
        try:
            import psutil
            process = psutil.Process()
            
            # è®°å½•åˆå§‹å†…å­˜
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB
            print(f"åˆå§‹å†…å­˜ä½¿ç”¨: {initial_memory:.1f} MB")
            
            # æ‰§è¡Œå¤§é‡æ“ä½œ
            large_data_count = 20
            records_per_stock = 1000
            
            print(f"åˆ›å»º {large_data_count} åªè‚¡ç¥¨çš„å¤§æ•°æ®é›†ï¼Œæ¯åªè‚¡ç¥¨ {records_per_stock} æ¡è®°å½•")
            
            for i in range(large_data_count):
                symbol = f"MEMORY{i:03d}"
                bars = []
                
                for j in range(records_per_stock):
                    bar = StockDailyBar(
                        date=date(2024, 1, (j % 28) + 1),
                        open_price=100.0 + j * 0.01,
                        close_price=100.1 + j * 0.01,
                        high_price=100.2 + j * 0.01,
                        low_price=99.9 + j * 0.01,
                        volume=1000000 + j * 100
                    )
                    bars.append(bar)
                
                stock_data = StockData(symbol=symbol, bars=bars)
                self.parquet_storage.save_stock_data(stock_data)
                
                # æ¯5ä¸ªæ•°æ®é›†æ£€æŸ¥ä¸€æ¬¡å†…å­˜
                if (i + 1) % 5 == 0:
                    current_memory = process.memory_info().rss / 1024 / 1024
                    print(f"  å¤„ç† {i+1} ä¸ªæ•°æ®é›†åå†…å­˜ä½¿ç”¨: {current_memory:.1f} MB")
            
            # è®°å½•æœ€ç»ˆå†…å­˜
            final_memory = process.memory_info().rss / 1024 / 1024
            memory_increase = final_memory - initial_memory
            
            print(f"\nå†…å­˜ä½¿ç”¨ç»Ÿè®¡:")
            print(f"  åˆå§‹å†…å­˜: {initial_memory:.1f} MB")
            print(f"  æœ€ç»ˆå†…å­˜: {final_memory:.1f} MB") 
            print(f"  å†…å­˜å¢é•¿: {memory_increase:.1f} MB")
            print(f"  å¹³å‡æ¯ä¸ªæ•°æ®é›†å†…å­˜å¼€é”€: {memory_increase / large_data_count:.2f} MB")
            
            # å†…å­˜ä½¿ç”¨æ–­è¨€
            assert memory_increase < 500, f"å†…å­˜å¢é•¿ {memory_increase:.1f}MB è¶…è¿‡500MBé™åˆ¶"
            
            print("âœ“ å†…å­˜ä½¿ç”¨æµ‹è¯•é€šè¿‡")
            
        except ImportError:
            print("âš ï¸  psutil æœªå®‰è£…ï¼Œè·³è¿‡å†…å­˜æµ‹è¯•")
        except Exception as e:
            print(f"âš ï¸  å†…å­˜æµ‹è¯•å¼‚å¸¸: {e}")
    
    def test_system_limits(self):
        """æµ‹è¯•ç³»ç»Ÿé™åˆ¶å’Œè¾¹ç•Œæ¡ä»¶"""
        print("\n=== ç³»ç»Ÿé™åˆ¶æµ‹è¯• ===")
        
        # æµ‹è¯•å¤§æ–‡ä»¶å¤„ç†
        print("æµ‹è¯•å¤§æ•°æ®é‡å¤„ç†...")
        large_symbol = "LARGE_DATA_TEST"
        large_record_count = 5000  # 5000æ¡è®°å½•
        
        try:
            bars = []
            for i in range(large_record_count):
                bar = StockDailyBar(
                    date=date(2024, 1, (i % 28) + 1),
                    open_price=100.0 + i * 0.001,
                    close_price=100.0 + i * 0.001 + 0.1,
                    high_price=100.0 + i * 0.001 + 0.2,
                    low_price=100.0 + i * 0.001 - 0.1,
                    volume=1000000 + i
                )
                bars.append(bar)
            
            large_stock_data = StockData(symbol=large_symbol, bars=bars)
            
            # æµ‹è¯•å­˜å‚¨å¤§æ–‡ä»¶
            start_time = time.time()
            self.parquet_storage.save_stock_data(large_stock_data)
            save_time = time.time() - start_time
            
            print(f"  âœ“ å­˜å‚¨ {large_record_count} æ¡è®°å½•è€—æ—¶: {save_time:.2f}ç§’")
            
            # æµ‹è¯•è¯»å–å¤§æ–‡ä»¶
            start_time = time.time()
            retrieved_data = self.parquet_storage.load_stock_data(large_symbol)
            load_time = time.time() - start_time
            
            print(f"  âœ“ è¯»å– {len(retrieved_data.bars)} æ¡è®°å½•è€—æ—¶: {load_time:.2f}ç§’")
            
            assert len(retrieved_data.bars) == large_record_count, "å¤§æ–‡ä»¶æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥"
            assert save_time < 10.0, f"å¤§æ–‡ä»¶å­˜å‚¨æ—¶é—´ {save_time:.2f}ç§’ è¶…è¿‡10ç§’é™åˆ¶"
            assert load_time < 5.0, f"å¤§æ–‡ä»¶è¯»å–æ—¶é—´ {load_time:.2f}ç§’ è¶…è¿‡5ç§’é™åˆ¶"
            
        except Exception as e:
            print(f"  âœ— å¤§æ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
            raise
        
        # æµ‹è¯•æ–‡ä»¶æ•°é‡é™åˆ¶
        print("æµ‹è¯•å¤§é‡æ–‡ä»¶å¤„ç†...")
        file_count = 100
        
        try:
            start_time = time.time()
            
            for i in range(file_count):
                symbol = f"MULTI{i:04d}"
                test_data = StockData(
                    symbol=symbol,
                    bars=[
                        StockDailyBar(
                            date=date(2024, 1, 1),
                            open_price=100.0,
                            close_price=101.0,
                            high_price=102.0,
                            low_price=99.0,
                            volume=1000000
                        )
                    ]
                )
                self.parquet_storage.save_stock_data(test_data)
            
            multi_file_time = time.time() - start_time
            print(f"  âœ“ åˆ›å»º {file_count} ä¸ªæ–‡ä»¶è€—æ—¶: {multi_file_time:.2f}ç§’")
            
            assert multi_file_time < 30.0, f"å¤šæ–‡ä»¶åˆ›å»ºæ—¶é—´ {multi_file_time:.2f}ç§’ è¶…è¿‡30ç§’é™åˆ¶"
            
        except Exception as e:
            print(f"  âœ— å¤šæ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
            raise
        
        print("âœ“ ç³»ç»Ÿé™åˆ¶æµ‹è¯•é€šè¿‡")


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæ€§èƒ½æµ‹è¯•
    test_suite = TestPerformance()
    test_suite.setup_test_environment()
    
    print("å¼€å§‹æ‰§è¡Œæ€§èƒ½å’Œå‹åŠ›æµ‹è¯•...")
    
    try:
        test_suite.test_data_fetch_performance()
        test_suite.test_storage_performance()
        test_suite.test_concurrent_operations()
        test_suite.test_memory_usage()
        test_suite.test_system_limits()
        
        print("\nğŸ‰ æ‰€æœ‰æ€§èƒ½æµ‹è¯•é€šè¿‡ï¼")
    except Exception as e:
        print(f"\nâŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        sys.exit(1)
