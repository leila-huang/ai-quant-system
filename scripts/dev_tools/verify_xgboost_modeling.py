#!/usr/bin/env python3
"""
XGBoostå»ºæ¨¡æ¡†æ¶éªŒè¯è„šæœ¬
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import tempfile
import shutil
from datetime import date, timedelta
import time
import numpy as np
import pandas as pd

from backend.src.models.basic_models import StockData, StockDailyBar
from backend.src.engine.modeling.xgb_wrapper import XGBoostModelFramework, create_default_xgboost_framework
from backend.src.engine.modeling.model_trainer import UnifiedModelTrainer, TrainingConfig, create_default_trainer
from backend.src.engine.modeling.model_evaluator import ComprehensiveModelEvaluator, create_default_evaluator
from backend.src.engine.modeling import PredictionTarget
from backend.src.engine.features.pipeline import create_default_pipeline
from backend.src.data.akshare_adapter import AKShareAdapter


def create_test_stock_data(symbol: str, days: int = 200) -> StockData:
    """åˆ›å»ºæµ‹è¯•è‚¡ç¥¨æ•°æ®"""
    base_date = date(2024, 1, 1)
    bars = []
    
    np.random.seed(hash(symbol) % 2147483647)  # åŸºäºè‚¡ç¥¨ä»£ç çš„å¯é‡å¤éšæœºç§å­
    
    base_price = 10.0 + np.random.random() * 20.0  # 10-30çš„åŸºç¡€ä»·æ ¼
    
    for i in range(days):
        # ç”Ÿæˆå…·æœ‰è¶‹åŠ¿å’Œæ³¢åŠ¨çš„ä»·æ ¼
        trend = np.sin(i * 0.01) * 0.05  # é•¿æœŸè¶‹åŠ¿
        momentum = np.random.normal(0, 0.02)  # åŠ¨é‡å› å­
        noise = np.random.normal(0, 0.01)  # éšæœºå™ªå£°
        
        price_change = trend + momentum + noise
        
        if i == 0:
            price = base_price
        else:
            price = max(bars[-1].close_price * (1 + price_change), 0.01)
        
        volume = int(1000 + np.random.exponential(800))  # æˆäº¤é‡å˜åŒ–
        
        bar = StockDailyBar(
            date=base_date + timedelta(days=i),
            open_price=price * (1 + np.random.normal(0, 0.005)),
            high_price=price * (1 + abs(np.random.normal(0, 0.015))),
            low_price=price * (1 - abs(np.random.normal(0, 0.015))),
            close_price=price,
            volume=volume,
            amount=price * volume * 100,
            adjust_factor=1.0
        )
        bars.append(bar)
    
    return StockData(
        symbol=symbol,
        name=f"æµ‹è¯•è‚¡ç¥¨{symbol}",
        bars=bars
    )


def test_basic_xgboost_functionality():
    """æµ‹è¯•XGBooståŸºæœ¬åŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•XGBooståŸºæœ¬åŠŸèƒ½...")
    
    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        stock_data = create_test_stock_data("000001", 150)
        
        # æµ‹è¯•ä¸åŒé¢„æµ‹ç›®æ ‡
        targets = [
            PredictionTarget.RETURN,
            PredictionTarget.DIRECTION, 
            PredictionTarget.PRICE
        ]
        
        success_count = 0
        
        for target in targets:
            try:
                print(f"  æµ‹è¯•é¢„æµ‹ç›®æ ‡: {target.value}")
                
                # åˆ›å»ºXGBoostæ¡†æ¶
                xgb_framework = XGBoostModelFramework(prediction_target=target)
                
                # å‡†å¤‡æ•°æ®
                X, y = xgb_framework.prepare_training_data(
                    stock_data.to_dataframe(),
                    lookback_window=30,
                    prediction_horizon=1
                )
                
                print(f"    æ•°æ®å‡†å¤‡å®Œæˆ: X{X.shape}, y{y.shape}")
                
                # è®­ç»ƒæ¨¡å‹
                xgb_framework.train(X, y, validation_split=0.2)
                
                # é¢„æµ‹
                predictions = xgb_framework.predict(X.iloc[-20:])  # é¢„æµ‹æœ€å20ä¸ªæ ·æœ¬
                
                # è·å–ç‰¹å¾é‡è¦æ€§
                importance = xgb_framework.get_feature_importance()
                
                print(f"    âœ… {target.value} é¢„æµ‹æˆåŠŸï¼Œé¢„æµ‹æ ·æœ¬: {len(predictions)}, é‡è¦ç‰¹å¾æ•°: {len(importance)}")
                success_count += 1
                
            except Exception as e:
                print(f"    âŒ {target.value} é¢„æµ‹å¤±è´¥: {e}")
        
        if success_count == len(targets):
            print("âœ… XGBooståŸºæœ¬åŠŸèƒ½æµ‹è¯•å…¨éƒ¨é€šè¿‡")
            return True
        else:
            print(f"âš ï¸ XGBooståŸºæœ¬åŠŸèƒ½æµ‹è¯•éƒ¨åˆ†é€šè¿‡: {success_count}/{len(targets)}")
            return success_count > 0
    
    except Exception as e:
        print(f"âŒ XGBooståŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_hyperparameter_optimization():
    """æµ‹è¯•è¶…å‚æ•°ä¼˜åŒ–"""
    print("\nğŸ”§ æµ‹è¯•è¶…å‚æ•°ä¼˜åŒ–...")
    
    try:
        # åˆ›å»ºè¾ƒå°çš„æ•°æ®é›†ç”¨äºå¿«é€Ÿæµ‹è¯•
        stock_data = create_test_stock_data("000002", 100)
        features_df = stock_data.to_dataframe()
        
        # åˆ›å»ºXGBoostæ¡†æ¶
        xgb_framework = XGBoostModelFramework(prediction_target=PredictionTarget.RETURN)
        
        # å‡†å¤‡æ•°æ®
        X, y = xgb_framework.prepare_training_data(features_df)
        
        print(f"  è¶…å‚æ•°ä¼˜åŒ–æ•°æ®å‡†å¤‡å®Œæˆ: {X.shape}")
        
        # å®šä¹‰å°å‚æ•°ç½‘æ ¼ä»¥åŠ å¿«æµ‹è¯•
        param_grid = {
            'max_depth': [3, 4],
            'learning_rate': [0.1, 0.2],
            'n_estimators': [50, 100]
        }
        
        start_time = time.time()
        best_params = xgb_framework.optimize_hyperparameters(
            X, y, 
            param_grid=param_grid,
            cv_folds=3
        )
        end_time = time.time()
        
        print(f"  âœ… è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ")
        print(f"    ä¼˜åŒ–æ—¶é—´: {end_time - start_time:.2f}ç§’")
        print(f"    æœ€ä¼˜å‚æ•°: {best_params}")
        print(f"    å‚æ•°æ•°é‡: {len(best_params)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¶…å‚æ•°ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_model_evaluation():
    """æµ‹è¯•æ¨¡å‹è¯„ä¼°"""
    print("\nğŸ“Š æµ‹è¯•æ¨¡å‹è¯„ä¼°...")
    
    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        stock_data = create_test_stock_data("000003", 120)
        
        # åˆ›å»ºè¯„ä¼°å™¨
        evaluator = ComprehensiveModelEvaluator()
        
        # åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
        xgb_framework = XGBoostModelFramework(prediction_target=PredictionTarget.RETURN)
        X, y = xgb_framework.prepare_training_data(stock_data.to_dataframe())
        xgb_framework.train(X, y, validation_split=0.3)
        
        # è¿›è¡Œé¢„æµ‹
        y_pred = xgb_framework.predict(X)
        
        print(f"  è¯„ä¼°æ•°æ®å‡†å¤‡å®Œæˆ: {len(y)} ä¸ªæ ·æœ¬")
        
        # è¯„ä¼°æ¨¡å‹
        evaluation_results = evaluator.evaluate(
            y.values, y_pred, 
            prediction_target=PredictionTarget.RETURN
        )
        
        print(f"  âœ… æ¨¡å‹è¯„ä¼°å®Œæˆï¼Œè®¡ç®—äº† {len(evaluation_results)} ä¸ªæŒ‡æ ‡")
        
        # æ˜¾ç¤ºä¸»è¦æŒ‡æ ‡
        key_metrics = ['r2', 'rmse', 'mae', 'sharpe_ratio', 'hit_rate']
        print("  ä¸»è¦è¯„ä¼°æŒ‡æ ‡:")
        for metric in key_metrics:
            if metric in evaluation_results:
                value = evaluation_results[metric]
                print(f"    {metric}: {value:.4f}")
        
        # æµ‹è¯•åˆ†ç±»è¯„ä¼°
        xgb_classifier = XGBoostModelFramework(prediction_target=PredictionTarget.DIRECTION)
        X_cls, y_cls = xgb_classifier.prepare_training_data(stock_data.to_dataframe())
        xgb_classifier.train(X_cls, y_cls)
        y_cls_pred = xgb_classifier.predict(X_cls)
        
        cls_results = evaluator.evaluate(
            y_cls.values, y_cls_pred,
            prediction_target=PredictionTarget.DIRECTION
        )
        
        print(f"  âœ… åˆ†ç±»è¯„ä¼°å®Œæˆï¼Œå‡†ç¡®ç‡: {cls_results.get('accuracy', 0):.4f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¯„ä¼°æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_model_persistence():
    """æµ‹è¯•æ¨¡å‹ä¿å­˜å’ŒåŠ è½½"""
    print("\nğŸ’¾ æµ‹è¯•æ¨¡å‹æŒä¹…åŒ–...")
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            # åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
            stock_data = create_test_stock_data("000004", 80)
            xgb_framework = XGBoostModelFramework(prediction_target=PredictionTarget.RETURN)
            
            X, y = xgb_framework.prepare_training_data(stock_data.to_dataframe())
            xgb_framework.train(X, y)
            
            # è®°å½•è®­ç»ƒåçš„é¢„æµ‹ç»“æœ
            original_predictions = xgb_framework.predict(X.iloc[-10:])
            original_importance = xgb_framework.get_feature_importance()
            
            print(f"  åŸå§‹æ¨¡å‹é¢„æµ‹æ ·æœ¬: {len(original_predictions)}")
            print(f"  åŸå§‹æ¨¡å‹ç‰¹å¾é‡è¦æ€§æ•°: {len(original_importance)}")
            
            # ä¿å­˜æ¨¡å‹
            model_path = os.path.join(temp_dir, "test_xgb_model.joblib")
            save_success = xgb_framework.save_model(model_path)
            
            if not save_success:
                raise Exception("æ¨¡å‹ä¿å­˜å¤±è´¥")
            
            print(f"  âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ: {model_path}")
            
            # åˆ›å»ºæ–°çš„æ¡†æ¶å®ä¾‹å¹¶åŠ è½½æ¨¡å‹
            new_framework = XGBoostModelFramework()
            load_success = new_framework.load_model(model_path)
            
            if not load_success:
                raise Exception("æ¨¡å‹åŠ è½½å¤±è´¥")
            
            print("  âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # éªŒè¯åŠ è½½çš„æ¨¡å‹
            loaded_predictions = new_framework.predict(X.iloc[-10:])
            loaded_importance = new_framework.get_feature_importance()
            
            # æ¯”è¾ƒé¢„æµ‹ç»“æœ
            prediction_diff = np.max(np.abs(original_predictions - loaded_predictions))
            
            if prediction_diff < 1e-10:
                print("  âœ… é¢„æµ‹ç»“æœä¸€è‡´æ€§éªŒè¯é€šè¿‡")
            else:
                print(f"  âš ï¸ é¢„æµ‹ç»“æœå­˜åœ¨å·®å¼‚ï¼Œæœ€å¤§å·®å¼‚: {prediction_diff}")
            
            # æ¯”è¾ƒç‰¹å¾é‡è¦æ€§
            if len(original_importance) == len(loaded_importance):
                print("  âœ… ç‰¹å¾é‡è¦æ€§ä¸€è‡´æ€§éªŒè¯é€šè¿‡")
            else:
                print("  âš ï¸ ç‰¹å¾é‡è¦æ€§æ•°é‡ä¸ä¸€è‡´")
            
            return True
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹æŒä¹…åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_unified_trainer():
    """æµ‹è¯•ç»Ÿä¸€æ¨¡å‹è®­ç»ƒå™¨"""
    print("\nğŸ“ æµ‹è¯•ç»Ÿä¸€æ¨¡å‹è®­ç»ƒå™¨...")
    
    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ® - å¤šåªè‚¡ç¥¨
        stock_data_list = [
            create_test_stock_data("000001", 100),
            create_test_stock_data("000002", 100),
            create_test_stock_data("600000", 100)
        ]
        
        # åˆå¹¶æ•°æ®
        dfs = [stock.to_dataframe() for stock in stock_data_list]
        combined_df = pd.concat(dfs, ignore_index=True)
        
        print(f"  ç»Ÿä¸€è®­ç»ƒå™¨æµ‹è¯•æ•°æ®: {combined_df.shape}")
        
        # åˆ›å»ºç‰¹å¾å·¥ç¨‹æµæ°´çº¿
        feature_pipeline = create_default_pipeline()
        
        # åˆ›å»ºç»Ÿä¸€è®­ç»ƒå™¨
        trainer = UnifiedModelTrainer(feature_pipeline=feature_pipeline)
        
        # å‡†å¤‡æ•°æ®
        data_info = trainer.prepare_data(combined_df)
        
        print(f"  æ•°æ®å‡†å¤‡å®Œæˆ:")
        print(f"    æ€»æ ·æœ¬æ•°: {data_info['total_samples']}")
        print(f"    ç‰¹å¾æ•°: {data_info['feature_count']}")
        print(f"    è®­ç»ƒ/éªŒè¯/æµ‹è¯•åˆ†å‰²: {data_info['splits']}")
        
        # è®­ç»ƒå•ä¸ªæ¨¡å‹
        xgb_model = XGBoostModelFramework(prediction_target=PredictionTarget.RETURN)
        training_results = trainer.train_model(
            xgb_model, 
            model_name="XGBoost_Return",
            prediction_target=PredictionTarget.RETURN
        )
        
        print(f"  âœ… å•æ¨¡å‹è®­ç»ƒå®Œæˆ")
        print(f"    è®­ç»ƒæ—¶é—´: {training_results['training_time']:.2f}ç§’")
        print(f"    éªŒè¯RÂ²: {training_results['validation_metrics'].get('r2', 0):.4f}")
        
        # æ‰¹é‡è®­ç»ƒå¤šä¸ªæ¨¡å‹
        model_configs = [
            {
                'name': 'XGBoost_Direction',
                'model_class': XGBoostModelFramework,
                'model_params': {'prediction_target': PredictionTarget.DIRECTION},
                'prediction_target': PredictionTarget.DIRECTION
            },
            {
                'name': 'XGBoost_Price', 
                'model_class': XGBoostModelFramework,
                'model_params': {'prediction_target': PredictionTarget.PRICE},
                'prediction_target': PredictionTarget.PRICE
            }
        ]
        
        batch_results = trainer.batch_train_models(model_configs)
        successful_models = [name for name, result in batch_results.items() if 'error' not in result]
        
        print(f"  âœ… æ‰¹é‡è®­ç»ƒå®Œæˆï¼ŒæˆåŠŸè®­ç»ƒ {len(successful_models)} ä¸ªæ¨¡å‹")
        
        # è·å–è®­ç»ƒæ€»ç»“
        summary = trainer.get_training_summary()
        print(f"  è®­ç»ƒæ€»ç»“: {len(summary['trained_models'])} ä¸ªæ¨¡å‹å·²è®­ç»ƒ")
        
        return len(successful_models) >= 1  # è‡³å°‘æˆåŠŸè®­ç»ƒä¸€ä¸ªæ¨¡å‹
        
    except Exception as e:
        print(f"âŒ ç»Ÿä¸€æ¨¡å‹è®­ç»ƒå™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_with_real_data():
    """ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•"""
    print("\nğŸŒ ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•...")
    
    try:
        # è·å–çœŸå®æ•°æ®
        adapter = AKShareAdapter()
        end_date = date.today()
        start_date = end_date - timedelta(days=120)
        
        print(f"æ­£åœ¨è·å–çœŸå®æ•°æ®: å¹³å®‰é“¶è¡Œ(000001) {start_date} åˆ° {end_date}")
        
        stock_data = adapter.get_stock_data("000001", start_date, end_date)
        
        if not stock_data or len(stock_data.bars) < 50:
            print("âŒ çœŸå®æ•°æ®ä¸è¶³ï¼Œè·³è¿‡æ­¤æµ‹è¯•")
            return True  # è·³è¿‡æµ‹è¯•è€Œä¸æ˜¯å¤±è´¥
        
        print(f"âœ… è·å–çœŸå®æ•°æ®æˆåŠŸï¼Œå…± {len(stock_data.bars)} ä¸ªäº¤æ˜“æ—¥")
        
        # ä½¿ç”¨ç‰¹å¾å·¥ç¨‹æµæ°´çº¿
        feature_pipeline = create_default_pipeline()
        features_df = feature_pipeline.fit_transform(stock_data)
        
        print(f"ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œç‰¹å¾ç»´åº¦: {features_df.shape}")
        
        # æµ‹è¯•ä¸åŒé¢„æµ‹ç›®æ ‡
        targets_to_test = [PredictionTarget.RETURN, PredictionTarget.DIRECTION]
        successful_targets = 0
        
        for target in targets_to_test:
            try:
                print(f"  æµ‹è¯•çœŸå®æ•°æ® - {target.value} é¢„æµ‹...")
                
                # åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
                xgb_framework = XGBoostModelFramework(prediction_target=target)
                X, y = xgb_framework.prepare_training_data(features_df)
                
                if len(X) < 30:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®
                    print(f"    è·³è¿‡ {target.value}ï¼šè®­ç»ƒæ•°æ®ä¸è¶³")
                    continue
                
                xgb_framework.train(X, y, validation_split=0.3)
                
                # é¢„æµ‹å’Œè¯„ä¼°
                predictions = xgb_framework.predict(X.iloc[-10:])
                
                # æ¨¡å‹è¯„ä¼°
                evaluator = ComprehensiveModelEvaluator()
                eval_results = evaluator.evaluate(y.values[-10:], predictions, target)
                
                # æ˜¾ç¤ºç»“æœ
                if target == PredictionTarget.RETURN:
                    key_metric = eval_results.get('r2', 0)
                    print(f"    âœ… æ”¶ç›Šç‡é¢„æµ‹å®Œæˆï¼ŒRÂ²: {key_metric:.4f}")
                else:
                    key_metric = eval_results.get('accuracy', 0)
                    print(f"    âœ… æ–¹å‘é¢„æµ‹å®Œæˆï¼Œå‡†ç¡®ç‡: {key_metric:.4f}")
                
                successful_targets += 1
                
            except Exception as e:
                print(f"    âŒ {target.value} é¢„æµ‹å¤±è´¥: {e}")
        
        print(f"çœŸå®æ•°æ®æµ‹è¯•å®Œæˆ: {successful_targets}/{len(targets_to_test)} ä¸ªé¢„æµ‹ç›®æ ‡æˆåŠŸ")
        return successful_targets > 0
        
    except Exception as e:
        print(f"âŒ çœŸå®æ•°æ®æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_model_comparison():
    """æµ‹è¯•æ¨¡å‹æ¯”è¾ƒåŠŸèƒ½"""
    print("\nğŸ”€ æµ‹è¯•æ¨¡å‹æ¯”è¾ƒåŠŸèƒ½...")
    
    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        stock_data = create_test_stock_data("000005", 150)
        features_df = stock_data.to_dataframe()
        
        # è®­ç»ƒå¤šä¸ªæ¨¡å‹
        models = {}
        evaluation_results = {}
        evaluator = ComprehensiveModelEvaluator()
        
        # æ¨¡å‹é…ç½®
        model_configs = [
            ('XGB_Return_v1', PredictionTarget.RETURN, {'max_depth': 3, 'learning_rate': 0.1}),
            ('XGB_Return_v2', PredictionTarget.RETURN, {'max_depth': 4, 'learning_rate': 0.05}),
            ('XGB_Direction', PredictionTarget.DIRECTION, {'max_depth': 3, 'learning_rate': 0.1})
        ]
        
        for model_name, target, params in model_configs:
            try:
                # åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
                xgb_framework = XGBoostModelFramework(
                    prediction_target=target, 
                    model_params=params
                )
                X, y = xgb_framework.prepare_training_data(features_df)
                xgb_framework.train(X, y, validation_split=0.25)
                
                # é¢„æµ‹å’Œè¯„ä¼°
                predictions = xgb_framework.predict(X)
                eval_results = evaluator.evaluate(y.values, predictions, target)
                
                models[model_name] = xgb_framework
                evaluation_results[model_name] = eval_results
                
                print(f"  âœ… æ¨¡å‹ {model_name} è®­ç»ƒå’Œè¯„ä¼°å®Œæˆ")
                
            except Exception as e:
                print(f"  âŒ æ¨¡å‹ {model_name} å¤±è´¥: {e}")
        
        if len(evaluation_results) < 2:
            print("  âš ï¸ å¯æ¯”è¾ƒçš„æ¨¡å‹ä¸è¶³ï¼Œè·³è¿‡æ¯”è¾ƒæµ‹è¯•")
            return len(evaluation_results) > 0
        
        # æ¯”è¾ƒæ¨¡å‹
        comparison_results = evaluator.compare_models(evaluation_results)
        
        print(f"  âœ… æ¨¡å‹æ¯”è¾ƒå®Œæˆ")
        print(f"    æ¯”è¾ƒäº† {comparison_results['summary']['models_compared']} ä¸ªæ¨¡å‹")
        print(f"    æœ€ä½³ç»¼åˆæ¨¡å‹: {comparison_results['summary']['best_overall_model']}")
        
        # æ˜¾ç¤ºå„æŒ‡æ ‡çš„æœ€ä½³æ¨¡å‹
        print("  å„æŒ‡æ ‡æœ€ä½³æ¨¡å‹:")
        for metric, (model_name, score) in comparison_results['best_model_per_metric'].items():
            print(f"    {metric}: {model_name} ({score:.4f})")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ¯”è¾ƒæµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ AIé‡åŒ–ç³»ç»Ÿ - XGBoostå»ºæ¨¡æ¡†æ¶éªŒè¯")
    print("=" * 80)
    
    test_functions = [
        test_basic_xgboost_functionality,
        test_hyperparameter_optimization,
        test_model_evaluation,
        test_model_persistence,
        test_unified_trainer,
        test_with_real_data,
        test_model_comparison
    ]
    
    results = []
    
    for test_func in test_functions:
        try:
            result = test_func()
            results.append(result)
        except Exception as e:
            print(f"âŒ æµ‹è¯• {test_func.__name__} å‘ç”Ÿå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            results.append(False)
    
    # æ±‡æ€»æµ‹è¯•ç»“æœ
    print("\n" + "=" * 80)
    passed_tests = sum(results)
    total_tests = len(results)
    
    print(f"æµ‹è¯•ç»“æœæ±‡æ€»:")
    for i, (test_func, result) in enumerate(zip(test_functions, results)):
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {i+1}. {test_func.__name__}: {status}")
    
    print(f"\næ€»ä½“ç»“æœ: {passed_tests}/{total_tests} é€šè¿‡")
    
    if passed_tests == total_tests:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼XGBoostå»ºæ¨¡æ¡†æ¶éªŒè¯æˆåŠŸï¼")
        print("\nğŸ“Š XGBoostå»ºæ¨¡æ¡†æ¶ç°å·²å‡†å¤‡å°±ç»ªï¼Œå…·å¤‡ä»¥ä¸‹èƒ½åŠ›:")
        print("   â€¢ å¤šç§é¢„æµ‹ç›®æ ‡æ”¯æŒï¼ˆæ”¶ç›Šç‡ã€æ–¹å‘ã€ä»·æ ¼é¢„æµ‹ï¼‰")
        print("   â€¢ è‡ªåŠ¨è¶…å‚æ•°ä¼˜åŒ–")
        print("   â€¢ å®Œå–„çš„æ¨¡å‹è¯„ä¼°ä½“ç³»")
        print("   â€¢ æ¨¡å‹ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½")
        print("   â€¢ ç»Ÿä¸€çš„è®­ç»ƒå™¨æ¥å£")
        print("   â€¢ çœŸå®æ•°æ®å…¼å®¹æ€§")
        print("   â€¢ æ¨¡å‹æ¯”è¾ƒå’Œé€‰æ‹©åŠŸèƒ½")
        return 0
    else:
        print(f"\nâš ï¸  æœ‰ {total_tests - passed_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
        return 1


if __name__ == "__main__":
    sys.exit(main())



